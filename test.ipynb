{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liusihan/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import jieba\n",
    "import copy\n",
    "from FlagEmbedding import FlagModel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ALL_PROXY=http://localhost:7890\n",
      "env: HTTP_PROXY=http://localhost:7890\n",
      "env: HTTPS_PROXY=http://localhost:7890\n"
     ]
    }
   ],
   "source": [
    "%env ALL_PROXY=http://localhost:7890\n",
    "%env HTTP_PROXY=http://localhost:7890\n",
    "%env HTTPS_PROXY=http://localhost:7890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 Connection established\n",
      "\n",
      "HTTP/2 200 \n",
      "\u001b[1mcontent-type\u001b[0m: text/html; charset=utf-8\n",
      "\u001b[1mcontent-length\u001b[0m: 111131\n",
      "\u001b[1mdate\u001b[0m: Thu, 10 Oct 2024 10:25:31 GMT\n",
      "\u001b[1mx-powered-by\u001b[0m: huggingface-moon\n",
      "\u001b[1mcross-origin-opener-policy\u001b[0m: same-origin\n",
      "\u001b[1mreferrer-policy\u001b[0m: strict-origin-when-cross-origin\n",
      "\u001b[1mx-request-id\u001b[0m: Root=1-6707ab9b-1ea778300d31a6f343eacf81\n",
      "\u001b[1mx-frame-options\u001b[0m: DENY\n",
      "\u001b[1metag\u001b[0m: W/\"1b21b-hq0i46Dx9p2hQmd3tOW1i4Z6aBg\"\n",
      "\u001b[1mvary\u001b[0m: Accept-Encoding\n",
      "\u001b[1mx-cache\u001b[0m: Hit from cloudfront\n",
      "\u001b[1mvia\u001b[0m: 1.1 1589faa614ba895d33dbc3abb71a5c7e.cloudfront.net (CloudFront)\n",
      "\u001b[1mx-amz-cf-pop\u001b[0m: ICN54-C2\n",
      "\u001b[1mx-amz-cf-id\u001b[0m: YZn65mg_QXUNyq4QXXL-O5QcRABXrmbn4Ev7EFZYUWuRZqa8pKP-_w==\n",
      "\u001b[1mage\u001b[0m: 51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.getenv(\"ALL_PROXY\")\n",
    "\n",
    "\n",
    "!curl -I https://huggingface.co\n",
    "model = FlagModel('BAAI/bge-large-zh-v1.5',\n",
    "                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "                  use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:1 text:1complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     21\u001b[0m     ans\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(text))\n\u001b[0;32m---> 22\u001b[0m     vectors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(file_num) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m text:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(text_num) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m     text_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/FlagEmbedding/flag_models.py:395\u001b[0m, in \u001b[0;36mFlagModel.encode\u001b[0;34m(self, sentences, batch_size, max_length, convert_to_numpy)\u001b[0m\n\u001b[1;32m    387\u001b[0m sentences_batch \u001b[38;5;241m=\u001b[39m sentences[start_index:start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m    388\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m    389\u001b[0m     sentences_batch,\n\u001b[1;32m    390\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m    394\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 395\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    396\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling(last_hidden_state, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_embeddings:\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DF-retrieval/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    437\u001b[0m )\n\u001b[0;32m--> 439\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with open('resources/train-v2.0.json', 'r') as file:\n",
    "#     squad_data = json.load(file)\n",
    "\n",
    "folder_path = 'D:\\\\桌面\\\\DM-DataFountain-Retrieval\\\\resources\\\\temp'\n",
    "output_path = 'D:\\\\桌面\\\\DM-DataFountain-Retrieval\\\\resources'\n",
    "\n",
    "# 遍历文件夹及其子文件夹中的所有文件\n",
    "vectors = []\n",
    "data = []\n",
    "\n",
    "file_num = 1\n",
    "text_num = 1\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text_num = 1\n",
    "            data = json.load(f)\n",
    "            for text in data:\n",
    "                vec = model.encode(text)\n",
    "                vectors.append(vec)\n",
    "                data.append({'content': text, 'vectors': vec})\n",
    "                print('file:' + str(file_num) + ' text:' + str(text_num) + 'complete')\n",
    "                text_num += 1\n",
    "            file_num += 1\n",
    "            \n",
    "with open(output_path + '/vectors', 'w') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: index for index, word in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path + '/word_index', 'w') as file:\n",
    "    for word, index in word_to_index.items():\n",
    "        file.write(word + ':' + str(index) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_vector(text):\n",
    "    words = jieba.lcut(text)\n",
    "    bow_vector = np.zeros(len(vocabulary))\n",
    "    for word in words:\n",
    "        if word in word_to_index:\n",
    "            bow_vector[word_to_index[word]] = 1    \n",
    "    return bow_vector\n",
    "\n",
    "\n",
    "paragraph_vectors = []\n",
    "paragraphs = []\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()  # 读取文件内容\n",
    "            paragraphs.append(copy.deepcopy(content))\n",
    "            paragraph_vectors.append(convert_text_to_vector(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path + '/paragraph_vectors', 'w') as file:\n",
    "    for text in paragraph_vectors:\n",
    "        for num in text:\n",
    "            file.write(str(num))\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7e1c25f944b0> >\n"
     ]
    }
   ],
   "source": [
    "dimension = len(vocabulary)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "# 将 NumPy 数组转换为 1 个二维数组\n",
    "paragraph_vectors = np.stack(paragraph_vectors).astype('float32')\n",
    "index.add(paragraph_vectors)\n",
    "print(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_paragraphs(search_term, num_results, index):\n",
    "    search_vector = convert_text_to_vector(search_term)\n",
    "    search_vector = np.array([search_vector]).astype('float32')\n",
    "    distances, indexes = index.search(search_vector, num_results)\n",
    "    for i, (distance, index) in enumerate(zip(distances[0], indexes[0])):\n",
    "        print(f\"Result {i+1}, Distance: {distance}\")\n",
    "        print(paragraphs[index])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1, Distance: 301.0\n",
      "本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况 不符，可能不具备现实意义，仅允许在本次比赛中使用。 中国联通成为北京2022年冬奥会和冬残奥会官方通信服务合作伙伴 发布时间：2017-12-26发布人：新闻发布人 12月26日晚间，在中国联通大厦里，中国联通的红色“中国结”与北京2022年冬奥会会徽和冬残奥会会徽的组合标志格外 醒目，中国联通与北京2022年冬奥会和冬残奥会组织委员会签约仪式在这里举行。这场签约，标志着中国联通正式成为北京 2022年冬奥会和冬残奥会官方通信服务合作伙伴，跻身于北京冬奥组委市场开发计划最高级别的赞助企业之列。 当晚，北京市副市长、北京冬奥组委执行副主席张建东，中国残联理事长、北京冬奥组委副主席鲁勇；中国联通董事长王 晓初，中国联通总经理陆益民，中国联通副总经理邵广禄出席签约仪式。北京冬奥组委秘书长韩子荣与中国联通副总经理买彦 州代表双方签署赞助协议。 北京市副市长、北京冬奥组委执行副主席张建东致辞表示，北京冬奥会是我国重要历史节点的重大标志性活动，对于展现 新时代国家形象、促进国家发展、振奋民族精神，具有重大而深远的意义。与通信服务企业开展合作，不仅是实施市场开发计 划的重要内容，也是高质量、高效率推进筹办工作的迫切需要。中国联通是我国电信事业的领军企业，拥有庞大的通信服务资 源和丰富的重大活动服务保障经验。北京冬奥组委将携手中国联通加强北京冬奥会与国内外各界的相联相通，努力打造智慧冬 奥、科技冬奥；同时，也会努力搭建推广平台，提供良好服务，使中国联通充分获得奥运品牌带来的广泛收益，助力企业更好 发展。 中国联通董事长王晓初在致辞中表示，近年来，在“网络强国”“数字中国”“互联网+行动计划”等国家战略的引领下，中国联 通坚持新发展理念，全面实施以“聚焦、创新、合作”为主要内涵的企业新战略。我们把致力于成为“客户信赖的智慧生活创造者” 作为企业愿景，把“联通世界 创享美好智慧生活”作为企业使命。奥运会的通信保障，联通着奥运健儿和热情观众，联通着好客 中国与广阔世界，联通着伟大复兴中国梦与现代奥运精神。中国联通将围绕“智慧冬奥、联通未来”这一主题，以智慧的网络、极 致的速率支撑奥运，以智慧的应用、丰富的产品服务奥运，以智慧的技术、专业的队伍保障奥运，为冬奥会的成功举办、为中 国力量的再次彰显，注入强劲新动能。 在签约仪式上，中国联通正式宣布启用166新号段，在全国投入百万个号码，以优质的网络、产品与服务持续助力中国通 信事业和中国奥运事业。 据了解，北京2022年冬奥会和冬残奥会市场开发计划自今年2月份启动以来，得到了社会各界的广泛关注和广大企业的踊 跃参与。目前，北京2022年冬奥会和冬残奥会官方合作伙伴已达五家，分别是中国银行、国航、伊利集团、安踏和中国联通。\n",
      "\n",
      "Result 2, Distance: 315.0\n",
      "本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况 不符，可能不具备现实意义，仅允许在本次比赛中使用。 加快数据要素开发，全面建设数智联通 发布时间：2024-07-22发布人：新闻宣传中心 7月20日，在以“向新同行，共创智能新时代”为主题的2024中国联通合作伙伴大会数据要素论坛上，集团数字化部孙世 臻总经理以《加快数据要素开发，全面建设数智联通》为主题发表演讲，展示了中国联通技术与业务深度融合的数字化转型实 践，以及联通数智产品、解决方案注智赋能千行百业的成效。 亮点一：十年磨剑，数智能力行业领先 坚持集约化协同发展，历经10年实现信息化向数智化的跨越，建成联通智慧大脑，形成一套联通云底座、五大中台、五 大运营平台、五大APP、N个场景的“1555N”数字化能力体系，建成了全球电信行业最大规模的核心业务系统cBSS，实现全云 化承载，核心业务全国发版不停业，开放超3万个中台能力高效支撑前端。 亮点二：久久为功，锻造差异化竞争优势 深入推进数字化转型，智慧运营水平显著提升。通过全国集约、全云化架构、行业领先的数字化能力，实现全集约赋能， 更加便捷。应用AI能力自动识别网络质量、网络服务等问题，实现全方位洞察，更加精准。深化“平台+应用+权益+X”产品模式， 实现全要素融合，更加敏捷。深度应用AI能力，打造新型人机协同工作台，实现全触点感知，更加全面。 亮点三：千锤百炼，数据管理水平进入国家第一梯队 按照“一套制度规范、一个数据中台、一套治理方法”原则，形成“1+12+N”数据管理制度和“1+13+N”企业标准规范，汇聚、 拉通、整合、共享全域数据，实现租户服务一点申请、一体交付，独创数据治理“七步法”，全面开展数据治理，对内服务千场万 景。 亮点四：持之以恒，实现数据血液千场万景贯通 坚持以治促用、以用促治，强化数据赋能，依托大数据多元汇聚与服务能力，形成智慧经分、全客运营、数字沙盘等应用， 加速数据融合流通，赋能超千个智慧运营场景。高质量数据集赋能AI建设，全面盘点企业内外部数据资源，形成高质量数据集， 用于元景通用大模型和网络、客服等行业模型的训练。 亮点五：激活价值，赋能千行百业转型升级 中国联通坚持以数智化为增长极推进市场业务发展，致力于通过自己的数智产品和服务，为各行各业提供转型升级的动力。 通过“联数网平台”和“可信数据资源空间”数据要素基础设施，深度赋能数据场景应用，激活数据要素价值潜能。构筑“云、大、 物、智、链、安” 聚合特色，加快数智融合应用规模化发展，全面服务数字中国“五位一体”总体布局。 面向未来，中国联通愿携手各合作伙伴，积极构建开放的合作生态，共同探索数智化转型的新路径，共享价值链、共建产 业链、共筑创新链，释放数据要素“乘数效应”，为数字经济发展汇聚众智众力！\n",
      "\n",
      "Result 3, Distance: 332.0\n",
      "本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况 不符，可能不具备现实意义，仅允许在本次比赛中使用。 中国联通全力做好四川雅江、云南临沧山火通信保障 发布时间： 发布人：新闻宣传中心 2024-03-18 3 月15日17 时许，四川省甘孜州雅江县呷拉镇白孜村发生了一起严重的森 林火灾。火势迅速蔓延，形成了巨大的威胁。次日，由于火场的风力突然增大， 火势进一步扩展，使得救援工作面临更加严峻的挑战。在这种紧急情况下，中国 联通四川省分公司立即启动了应急保障预案，指挥甘孜分公司积极投入到抢险救 灾的工作中，并紧急调度雅安分公司的力量前往甘孜进行支援。 中国联通甘孜分公司迅速组建了一支应急抢险保障队伍，奔赴火灾现场，为 救援工作提供坚实的通信保障。这支队伍不仅包括21 名经验丰富的抢险人员， 还配备了7 辆应急保障车、1 辆卫星基站车以及 2 套卫星便携基站。他们在火灾 现场迅速开通了26 个基站，并在雅江县呷拉镇的森林火灾现场指挥部建立了一 个卫星应急站，为救援指挥和抢险队伍提供了可靠的通信支持。 此外，中国联通还组织了6 名保障人员、2 辆卫星基站车和3台高通量便携 式卫星站，采取卫星基站车和便携式卫星站靠前进行通信信号补盲的方式，确保 指挥部和抢险队伍的通信畅通。这种灵活而高效的通信保障措施，使得救援工作 能够顺利进行，大大提高了抢险救灾的效率。与此同时，云南省临沧市临翔区圈 内乡斗阁村也在3 月16日18 时10 分许发生了一起森林火灾，过火面积约5.33 公顷。面对这场突如其来的灾害，中国联通云南省分公司和临沧分公司立即行动起来，及时安排了应急通信保障力量前往现场，加强了通信设施的巡检工作，并 严格执行7×24小时值班值守制度，确保通信网络的畅通无阻。为了应对火灾带 来的通信挑战，中国联通云南分公司与其他通信运营商紧密合作，协同联动，共 同保障现场通信网络的稳定运行。 截至目前，联通的传输线路和无线基站运行正常，没有受到火灾的影响，移 动固网语音和数据业务也保持正常运转。这一系列保障措施，为现场救援工作提 供了强有力的通信支持。火情发生后，中国联通迅速反应，全面启动了应急通信 保障预案。这不仅体现了联通公司在突发事件面前的快速反应能力，也展示了其 强大的应急通信保障实力。无论是四川雅江还是云南临沧，中国联通都展现出了 其作为国家大型通信企业的社会责任感和技术优势。 在接下来的日子里，中国联通将继续与当地政府部门保持密切联系，加强值 班值守和网络监测，为救援现场提供坚实的网络保障。同时，联通公司还将总结 此次应急保障工作的经验，不断提升应急通信保障能力，以更好地应对未来可能 发生的各种突发事件。 通过此次应急通信保障工作，中国联通不仅为救援工作提供了有力的支持， 也为当地居民的生命财产安全提供了坚实的保障。未来，中国联通将继续秉持“人 民至上，生命至上”的理念，履行社会责任，发挥技术优势，为保障人民群众的 安全和社会的和谐稳定贡献力量。\n",
      "\n",
      "Result 4, Distance: 402.0\n",
      "本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况 不符，可能不具备现实意义，仅允许在本次比赛中使用。 中国联通：同题共答 同向发力 以严督实导推动主题教育扎实开展 发布时间：2023-06-01发布人：新闻宣传中心 为推动学习贯彻习近平新时代中国特色社会主义思想主题教育各项任务落细落实、见行见效，进一步加强对主题教育的工 作指导和督促检查，中国联通党组结合自身党组织数量多、党员基数大和覆盖面广等实际情况，迅速组建5个巡回指导组，强 化对全集团各单位主题教育开展情况的督查指导。各巡回指导组切实加强自身建设，深入开展交流研讨、实地调研，注重分类 指导、精准督导，以更高标准、更严要求、更实作风为高质量开展主题教育提供有力保障。 凝心聚魂 学习充电强本领 4月20-21日，中国联通召开主题教育巡回指导组培训会，结合实际制定《巡回指导工作方案》《巡回指导组工作手册》， 安排部署相关工作并提出明确要求。打铁还需自身硬。各巡回指导组坚持先学一步，力求深学一层，做到多悟一分，通过集中 学习、现场教学、组员自学等方式，认真学习习近平新时代中国特色社会主义思想，学习习近平总书记关于网络强国、数字中 国、实现高水平科技自立自强等方面的重要论述及习近平总书记关于国有企业改革发展和党的建设系列重要讲话精神，全面提 升政治理论水平，增强做好巡回指导工作的责任感使命感。各巡回指导组在学习掌握工作方法、工作要求、督导管理等内容的 基础上，研讨制定巡回指导工作计划，确保工作职责明确、任务事项清晰，为高质高效开展巡回指导工作提供组织保障。 实事求是 分类指导促提升 各巡回指导组充分考虑被指导单位的差异性，坚持具体问题具体分析，借鉴以往集中教育督导工作经验，紧密结合此次主 题教育的新特点新要求，分类指导、精准督促，推动各单位将“七项关键工作”落实落细。第一巡回指导组按照被指导单位党委、 党总支部、党支部三类建制情况，划分三个小组开展分类指导，推动巡回指导工作规范化、精细化。第二巡回指导组与被指导 单位深入沟通，全面客观掌握实际情况，给出务实管用的指导意见建议。第三巡回指导组采用“统筹各方 分工协调”的工作模式， 按地域划分被指导单位，建立两个小组，确保指导工作同步推进。第四巡回指导组坚持集体指导和分工负责相结合，做到信息 收集点对点，经验分享多对多，指导沟通面对面。第五巡回指导组协助被指导单位聚焦典型问题，解剖麻雀、精准发力，扎实 推动问题整改落实。 稳扎稳打 深入调研谋发展 各巡回指导组深入基层、沉到一线，采取听取汇报、实地走访、查阅资料、谈话了解等方式，通过多层次、多方位、多渠 道的调查研究，掌握第一手信息，发挥好承上启下、帮助促进、把关督导和宣传引导作用，把情况摸清、把问题找准、把对策 提实，推动主题教育取得实实在在的成效。第一巡回指导组通过调研、查摆、指导，与被指导单位一起研究问题，探讨解决问 题的举措办法，共同推动主题教育落地落实。第二巡回指导组坚持与被指导单位同题共答、同力共促，结合被指导单位特点制 定个性化调研方案，以求实效。第三巡回指导组把指导工作与服务基层结合起来，在调研过程中强化与被指导单位的双向沟通。 第四巡回指导组带着课题、带着责任、带着使命、带着感情开展调研，务求调研“深、实、细、准、效”。第五巡回指导组采用“基 本课题+自选课题”的方式确定调研选题，集众智、汇众力，指导各单位在调查研究中找到破解难题的路径方法。 中国联通党组将紧扣深入学习贯彻习近平新时代中国特色社会主义思想这条主线，持之以恒提高主题教育巡回指导工作质 量，充分发挥传导压力、激发动力、挖掘潜力的作用，对规定动作严督实导，在加强分类指导上下功夫，重点督促整改落实， 确保主题教育全过程标准不降、力度不减、尺度不松，有力有效推动中国联通主题教育走深走实。\n",
      "\n",
      "Result 5, Distance: 405.0\n",
      "本文档为2024CCFBDCI比赛用语料的一部分。部分文档使用大语言模型改写生成，内容可能与现实情况 不符，可能不具备现实意义，仅允许在本次比赛中使用。 中国联通人工智能创新发展论坛在上海成功举办 发布时间：2024年7月20日 2024年7月19日，在中国联通合作伙伴大会期间，成功举办了人工智能创新发展论坛。 上海市经信委副主任张宏韬、中国联通总经理简勤、GSMA中华区总裁斯寒出席论坛并致辞； 中国工程院院士谭建荣，加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩，联 通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波，中国联通人工智能科学 家兼人工智能技术总师廉士国，中国联通数字化部副总经理娄瑜发表主旨演讲。 上海市经信委副主任张宏韬在致辞中表示，中国联通作为中央企业，深入贯彻落实国家 “人工智能+”专项行动，在人工智能领域取得了令人瞩目的成就，中国联通人工智能创新中 心充分利用中国联通在网、算、云、数、智、端、业的融合优势，推动了人工智能创新应用 规模化发展，展现了央企在新时代的责任与担当。上海市人民政府也高度重视人工智能的发 展，致力于打造开放的创新平台，吸引全球人工智能企业和人才汇聚，共同推动技术交流和 国际合作。 中国联通总经理简勤在致辞中表示，元景2.0不仅是中国联通人工智能技术的升级，更 是对人工智能创新发展的展望和承诺，是我们向智能时代更进一步的探索与实践。中国联通 高度重视人工智能产业生态建设，联合产业合作伙伴，共同推动AI与产业深度融合，形成 30多个元景行业大模型，赋能城市治理、工业制造等领域成效明显。未来，将携手各界， 强化技术共研、推动能力共建、促进应用共创、实现合作共赢，以人工智能引领经济社会各 领域从数字化、网络化向智能化跃升。 在同日上午举办的合作伙伴大会主峰会上，简勤正式发布了元景大模型2.0，元景2.0 展现了文生视频、图像可控生成等多项业界先进的多模态能力。 联通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波发表了题为“元景 大模型：更懂行业的模型，产业升级的智能引擎”的主题演讲。推出了元景2.0的基座能力、 MaaS平台、安全能力、行业应用四项能力升级，发布了2040亿元景多模态大模型、元景 文生图大模型、元景语音大模型三大基础模型，介绍了已取得中国信息通信研究院评级最高 等级认证的元景2.0核心组件RAG（检索增强生成）和智能体，展示了元景35+行业大模型、 100+标杆案例的落地成果。朱常波表示，经过长期的技术发展与案例实践，联通元景已获 得客户的普遍认可，获得了“更懂行业的大模型，产业升级的智能引擎”的口碑。 中国联通人工智能科学家兼人工智能技术总师廉士国发布了元景标准产品。廉士国介绍 了标准产品的布局，重磅发布了元景MaaS平台的八大通用组件，推出了元景热线、元景编 程、元景运维、元景办公四大通用产品，发布了元景大模型一体机。廉士国表示，中国联通 本次发布的创新产品和解决方案，将为各行业的数字化转型及智能化发展提供强有力的支持。中国联通数字化部副总经理娄瑜发布了中国联通人工智能共享数据集。人工智能共享数 据集是中国联通元景大模型高质高效发展的核心动能，其面向移动通信、政务、新型工业化 等重点行业，拥有大规模、多模态、高质量、强安全的核心优势。娄瑜表示，中国联通愿携 同行业合作伙伴，共同探索共建共享的人工智能数据集生态链。 中国工程院院士谭建荣发表了题为“人工智能大模型的内涵、关键技术与发展趋势”的主 题演讲；加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩发表了题为“构建算 力智联新体系，迈向大模型即服务新时代”的主题演讲。 论坛上，中国联通牵头成立了“人工智能大模型需求与场景应用创新联合体”“人工智能大 模型生态融合创新联合体”两大联合体，启动了“人工智能基础研究共研行动”“人工智能应用 创新基地共建行动”两项行动，提出了“共建高质量人工智能数据集合作倡议”。这一系列关键 举措体现了中国联通积极联合产学研投用各领域打造人工智能融合创新生态的决心。 最后，来自各行业的中国联通客户分享了元景大模型的实践案例，包括文创、政务、城 市治理、渔业、装备制造、医疗健康等行业，彰显了中国联通元景大模型赋能千行百业的卓 越能力。在此次合作伙伴大会期间，中国联通还在展区展示了可互动的元景政务、工业、文 创等一系列亮点大模型，吸引了参会嘉宾的目光，取得了良好的展示效果。 人工智能是新一轮科技革命和产业变革的重要驱动力量，是推动我国科技跨越发展、产 业优化升级的重要战略资源。未来，中国联通将继续勇担以人工智能推进网络强国、数字中 国建设的重要使命，携手各方行业同仁、合作伙伴共筑人工智能产业新高地，深化务实合作， 共同奋楫笃行新征程，为推动国家人工智能产业创新发展贡献力量。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_for_paragraphs('根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？', 5, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DF-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
